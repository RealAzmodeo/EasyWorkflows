{
    "1": {
        "inputs": {
            "upscale_by": 2,
            "upscale_model": [
                "2",
                0
            ],
            "image": "example.png"
        },
        "class_type": "ImageUpscaleWithModel"
    },
    "2": {
        "inputs": {
            "upscale_model": "4x-UltraSharp.safetensors"
        },
        "class_type": "UpscaleModelLoader"
    },
    "3": {
        "inputs": {
            "upscale_by": 1.5,
            "seed": 0,
            "steps": 20,
            "cfg": 7,
            "sampler_name": "euler",
            "scheduler": "normal",
            "denoise": 0.35,
            "mode_type": "Linear",
            "tile_width": 512,
            "tile_height": 512,
            "mask_blur": 8,
            "tile_padding": 32,
            "seam_fix_mode": "None",
            "seam_fix_denoise": 1,
            "seam_fix_width": 64,
            "seam_fix_mask_blur": 8,
            "seam_fix_padding": 16,
            "force_uniform_tiles": true,
            "tiled_decode": false,
            "image": [
                "1",
                0
            ],
            "model": [
                "4",
                0
            ],
            "positive": [
                "5",
                0
            ],
            "negative": [
                "6",
                0
            ],
            "vae": [
                "7",
                0
            ],
            "upscale_model": [
                "2",
                0
            ]
        },
        "class_type": "UltimateSDUpscale"
    },
    "4": {
        "inputs": {
            "ckpt_name": "realisticVisionV60B1_v51VAE.safetensors"
        },
        "class_type": "CheckpointLoaderSimple"
    },
    "5": {
        "inputs": {
            "text": "high quality, detailed, 8k",
            "clip": [
                "4",
                1
            ]
        },
        "class_type": "CLIPTextEncode"
    },
    "6": {
        "inputs": {
            "text": "blurry, low quality, watermarks",
            "clip": [
                "4",
                1
            ]
        },
        "class_type": "CLIPTextEncode"
    },
    "7": {
        "inputs": {
            "vae_name": "vae-ft-mse-840000-ema-pruned.safetensors"
        },
        "class_type": "VAELoader"
    },
    "8": {
        "inputs": {
            "filename_prefix": "Upscale",
            "images": [
                "3",
                0
            ]
        },
        "class_type": "SaveImage"
    }
}